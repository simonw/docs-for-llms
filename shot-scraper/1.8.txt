<documents>
<document index="1">
<source>docs/accessibility.md</source>
<document_content>
(accessibility)=

# Dumping out an accessibility tree

The `shot-scraper accessibility` command dumps out the Chromium accessibility tree for the provided URL, as JSON:
```bash
shot-scraper accessibility https://datasette.io/
```
Use `-o filename.json` to write the output to a file instead of displaying it.

Add `--javascript SCRIPT` to execute custom JavaScript before taking the snapshot.

## `shot-scraper accessibility --help`

Full `--help` for this command:

<!-- [[[cog
import cog
from shot_scraper import cli
from click.testing import CliRunner
runner = CliRunner()
result = runner.invoke(cli.cli, ["accessibility", "--help"])
help = result.output.replace("Usage: cli", "Usage: shot-scraper")
cog.out(
    "```\n{}\n```\n".format(help.strip())
)
]]] -->
```
Usage: shot-scraper accessibility [OPTIONS] URL

  Dump the Chromium accessibility tree for the specifed page

  Usage:

      shot-scraper accessibility https://datasette.io/

Options:
  -a, --auth FILENAME    Path to JSON authentication context file
  -o, --output FILENAME
  -j, --javascript TEXT  Execute this JS prior to taking the snapshot
  --timeout INTEGER      Wait this many milliseconds before failing
  --log-console          Write console.log() to stderr
  --fail                 Fail with an error code if a page returns an HTTP error
  --skip                 Skip pages that return HTTP errors
  --bypass-csp           Bypass Content-Security-Policy
  --auth-password TEXT   Password for HTTP Basic authentication
  --auth-username TEXT   Username for HTTP Basic authentication
  --help                 Show this message and exit.
```
<!-- [[[end]]] -->

</document_content>
</document>
<document index="2">
<source>docs/authentication.md</source>
<document_content>
(authentication)=

# Websites that need authentication

If you want to take screenshots of a site that has some form of authentication, you will first need to authenticate with that website manually.

You can do that using the `shot-scraper auth` command:
```bash
shot-scraper auth \
  https://datasette-auth-passwords-demo.datasette.io/-/login \
  auth.json
```
(For this demo, use username = `root` and password = `password!`)

This will open a browser window on your computer showing the page you specified.

You can then sign in using that browser window - including 2FA or CAPTCHAs or other more complex form of authentication.

When you are finished, hit `<enter>` at the `shot-scraper` command-line prompt. The browser will close and the authentication credentials (usually cookies) for that browser session will be written out to the `auth.json` file.

To take authenticated screenshots you can then use the `-a` or `--auth` options to point to the JSON file that you created:
```bash
shot-scraper https://datasette-auth-passwords-demo.datasette.io/ \
  -a auth.json -o authed.png
```
## `shot-scraper auth --help`

Full `--help` for `shot-scraper auth`:

<!-- [[[cog
import cog
from shot_scraper import cli
from click.testing import CliRunner
runner = CliRunner()
result = runner.invoke(cli.cli, ["auth", "--help"])
help = result.output.replace("Usage: cli", "Usage: shot-scraper")
cog.out(
    "```\n{}\n```\n".format(help.strip())
)
]]] -->
```
Usage: shot-scraper auth [OPTIONS] URL CONTEXT_FILE

  Open a browser so user can manually authenticate with the specified site, then
  save the resulting authentication context to a file.

  Usage:

      shot-scraper auth https://github.com/ auth.json

Options:
  -b, --browser [chromium|firefox|webkit|chrome|chrome-beta]
                                  Which browser to use
  --browser-arg TEXT              Additional arguments to pass to the browser
  --user-agent TEXT               User-Agent header to use
  --devtools                      Open browser DevTools
  --log-console                   Write console.log() to stderr
  --help                          Show this message and exit.
```
<!-- [[[end]]] -->

</document_content>
</document>
<document index="3">
<source>docs/contributing.md</source>
<document_content>
(contributing)=

# Contributing

The GitHub repository for this project is [simonw/shot-scraper](https://github.com/simonw/shot-scraper).

To contribute to this tool, first checkout the code. Then create a new virtual environment:
```bash
cd shot-scraper
python -m venv venv
source venv/bin/activate
```
Or if you are using `pipenv`:
```bash
pipenv shell
```
Now install the dependencies and test dependencies:
```bash
pip install -e '.[test]'
```
Then you'll need to install the Playwright browsers too:
```bash
shot-scraper install
```
To run the tests:
```bash
pytest
```
Some of the tests exercise the CLI utility directly. Run those like so:
```bash
tests/run_examples.sh
```
## Documentation

Documentation for this project uses [MyST](https://myst-parser.readthedocs.io/) - it is written in Markdown and rendered using Sphinx.

To build the documentation locally, run the following:
```bash
cd docs
pip install -r requirements.txt
make livehtml
```
This will start a live preview server, using [sphinx-autobuild](https://pypi.org/project/sphinx-autobuild/).

The CLI `--help` examples in the documentation are managed using [Cog](https://github.com/nedbat/cog). Update those files like this:
```bash
cog -r docs/*.md
```
## Publishing the release notes

After pushing a release, I use the following to create a screenshot of the release notes to use in social media posts:
```bash
shot-scraper https://github.com/simonw/shot-scraper/releases/tag/0.15 \
  --selector '.Box-body' --width 700 \
  --retina
```
[Example post](https://twitter.com/simonw/status/1569431710345089024).

</document_content>
</document>
<document index="4">
<source>docs/github-actions.md</source>
<document_content>
# Using shot-scraper with GitHub Actions

`shot-scraper` was designed with GitHub Actions for screenshot automation in mind.

## shot-scraper-template

The [shot-scraper-template](https://github.com/simonw/shot-scraper-template) template repository can be used to quickly create your own GitHub repository with GitHub Actions configured to take screenshots of a page and write it back to the repository. Read [Instantly create a GitHub repository to take screenshots of a web page](https://simonwillison.net/2022/Mar/14/shot-scraper-template/) for details.

## Building a workflow from scratch

This Actions workflow can be used to install `shot-scraper` and its dependencies, take screenshots defined in the `shots.yml` file in that repository and then write the resulting screenshots back to the same repository:

```yaml
name: Take screenshots

on:
  push:
  workflow_dispatch:

permissions:
  contents: write

jobs:
  shot-scraper:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python 3.10
      uses: actions/setup-python@v3
      with:
        python-version: "3.10"
    - uses: actions/cache@v3
      name: Configure pip caching
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip
    - name: Cache Playwright browsers
      uses: actions/cache@v3
      with:
        path: ~/.cache/ms-playwright/
        key: ${{ runner.os }}-playwright
    - name: Install dependencies
      run: |
        pip install shot-scraper
        shot-scraper install
    - name: Take shots
      run: |
        shot-scraper multi shots.yml
    - name: Commit and push
      run: |-
        git config user.name "Automated"
        git config user.email "actions@users.noreply.github.com"
        git add -A
        timestamp=$(date -u)
        git commit -m "${timestamp}" || exit 0
        git pull --rebase
        git push
```
The `actions/cache@v3` steps set up [caching](https://github.com/actions/cache), so your workflow will only download and install the necessary software the very first time it runs.

## Optimizing PNGs using Oxipng

You can losslessy compress the PNGs generated using `shot-scraper` by running them through [Oxipng](https://github.com/shssoichiro/oxipng). Add the following steps to the beginning of your workflow to install Oxing:

```yaml
    - name: Cache Oxipng
      uses: actions/cache@v3
      with:
        path: ~/.cargo/
        key: ${{ runner.os }}-cargo
    - name: Install Oxipng if it is not installed
      run: |
        which oxipng || cargo install oxipng
```

Then after running `shot-scraper` add this step to compress the images:

```yaml
    - name: Optimize PNGs
      run: |-
        oxipng -o 4 -i 0 --strip safe *.png
```

[simonw/datasette-screenshots](https://github.com/simonw/datasette-screenshots) is an example of a repository that uses this pattern.

See [Optimizing PNGs in GitHub Actions using Oxipng](https://til.simonwillison.net/github-actions/oxipng) for more on how this works.


</document_content>
</document>
<document index="5">
<source>docs/har.md</source>
<document_content>
(har)=

# Saving a web page to an HTTP Archive

An HTTP Archive file captures the full details of a series of HTTP requests and responses as JSON.

The `shot-scraper har` command can save a `*.har.zip` file that contains both that JSON data and the content of any assets that were loaded by the page.
```bash
shot-scraper har https://datasette.io/
```
This will save to `datasette-io.har`. You can use `-o` to specify a filename:
```bash
shot-scraper har https://datasette.io/tutorials/learn-sql \
  -o learn-sql.har
```
A `.har` file is JSON. You can view it using the [Google HAR Analyzer](https://toolbox.googleapps.com/apps/har_analyzer/) tool.

HTTP Archives can also be created as `.har.zip` files. These have a slightly different format: the `har.har` JSON does not include the full content of the responses, which is instead stored as separate files inside the `.zip`.

To create one of these, either add the `--zip` flag:

```bash
shot-scraper har https://datasette.io/ --zip
```
Or specify a filename that ends in `.har.zip`:
```bash
shot-scraper har https://datasette.io/ -o datasette-io.har.zip
```

You can view the contents of a HAR zip file using `unzip -l`:
```bash
unzip -l datasette-io.har.zip
```
```
Archive:  datasette-io.har.zip
  Length      Date    Time    Name
---------  ---------- -----   ----
    39067  02-13-2025 10:33   41824dbd0c51f584faf0e2c4e88de01b8a5dcdcd.html
     4052  02-13-2025 10:33   34972651f161f0396c697c65ef9aaeb2c9ac50c4.css
     2501  02-13-2025 10:33   9f612e71165058f0046d8bf8fec12af7eb15f39d.css
    10916  02-13-2025 10:33   2737174596eafba6e249022203c324605f023cdd.svg
     5557  02-13-2025 10:33   427504aa6ef5a8786f90fb2de636133b3fc6d1fe.js
     1393  02-13-2025 10:33   25c68a82b654c9d844c604565dab4785161ef697.js
     1170  02-13-2025 10:33   31c073551ef5c84324073edfc7b118f81ce9a7d2.svg
     1158  02-13-2025 10:33   1e0c64af7e6a4712f5e7d1917d9555bbc3d01f7a.svg
     1161  02-13-2025 10:33   ec8282b36a166d63fae4c04166bb81f945660435.svg
     3373  02-13-2025 10:33   5f85a11ef89c0e3f237c8e926c1cb66727182102.svg
     1134  02-13-2025 10:33   3b9d8109b919dfe9393dab2376fe03267dadc1f1.svg
    31670  02-13-2025 10:33   469f0d28af6c026dcae8c81731e2b0484aeac92c.jpeg
     1157  02-13-2025 10:33   b7786336bfce38a9677d26dc9ef468bb1ed45e19.svg
    50494  02-13-2025 10:33   har.har
---------                     -------
   154803                     14 files
```

You can record multiple pages to a single HTTP Archive using the {ref}`shot-scraper multi --har option<multi-har>`.

## `shot-scraper har --help`

Full `--help` for this command:

<!-- [[[cog
import cog
from shot_scraper import cli
from click.testing import CliRunner
runner = CliRunner()
result = runner.invoke(cli.cli, ["har", "--help"])
help = result.output.replace("Usage: cli", "Usage: shot-scraper")
cog.out(
    "```\n{}\n```\n".format(help.strip())
)
]]] -->
```
Usage: shot-scraper har [OPTIONS] URL

  Record a HAR file for the specified page

  Usage:

      shot-scraper har https://datasette.io/

  This defaults to saving to datasette-io.har - use -o to specify a different
  filename:

      shot-scraper har https://datasette.io/ -o trace.har

  Use --zip to save as a .har.zip file instead, or specify a filename ending in
  .har.zip

Options:
  -z, --zip              Save as a .har.zip file
  -a, --auth FILENAME    Path to JSON authentication context file
  -o, --output FILE      HAR filename
  --wait INTEGER         Wait this many milliseconds before taking the
                         screenshot
  --wait-for TEXT        Wait until this JS expression returns true
  -j, --javascript TEXT  Execute this JavaScript on the page
  --timeout INTEGER      Wait this many milliseconds before failing
  --log-console          Write console.log() to stderr
  --fail                 Fail with an error code if a page returns an HTTP error
  --skip                 Skip pages that return HTTP errors
  --bypass-csp           Bypass Content-Security-Policy
  --auth-password TEXT   Password for HTTP Basic authentication
  --auth-username TEXT   Username for HTTP Basic authentication
  --help                 Show this message and exit.
```
<!-- [[[end]]] -->

</document_content>
</document>
<document index="6">
<source>docs/html.md</source>
<document_content>
(html)=

# Dumping the HTML of a page

The `shot-scraper html` command dumps out the final HTML of a page after all JavaScript has run.
```bash
shot-scraper html https://datasette.io/
```
Use `-o filename.html` to write the output to a file instead of displaying it.
```bash
shot-scraper html https://datasette.io/ -o index.html
```
Add `--javascript SCRIPT` to execute custom JavaScript before taking the HTML snapshot.
```bash
shot-scraper html https://datasette.io/ \
  --javascript "document.querySelector('h1').innerText = 'Hello, world!'"
```
## Retrieving the HTML for a specific element

You can use the `-s SELECTOR` option to capture just the HTML for one specific element on the page, identified using a CSS selector:
```bash
shot-scraper html https://datasette.io/ -s h1
```
This outputs:
```html
<h1>
  <img class="datasette-logo" src="/static/datasette-logo.svg" alt="Datasette">
</h1>
```
## `shot-scraper html --help`

Full `--help` for this command:

<!-- [[[cog
import cog
from shot_scraper import cli
from click.testing import CliRunner
runner = CliRunner()
result = runner.invoke(cli.cli, ["html", "--help"])
help = result.output.replace("Usage: cli", "Usage: shot-scraper")
cog.out(
    "```\n{}\n```\n".format(help.strip())
)
]]] -->
```
Usage: shot-scraper html [OPTIONS] URL

  Output the final HTML of the specified page

  Usage:

      shot-scraper html https://datasette.io/

  Use -o to specify a filename:

      shot-scraper html https://datasette.io/ -o index.html

Options:
  -a, --auth FILENAME             Path to JSON authentication context file
  -o, --output FILE
  -j, --javascript TEXT           Execute this JS prior to saving the HTML
  -s, --selector TEXT             Return outerHTML of first element matching
                                  this CSS selector
  --wait INTEGER                  Wait this many milliseconds before taking the
                                  snapshot
  --log-console                   Write console.log() to stderr
  -b, --browser [chromium|firefox|webkit|chrome|chrome-beta]
                                  Which browser to use
  --browser-arg TEXT              Additional arguments to pass to the browser
  --user-agent TEXT               User-Agent header to use
  --fail                          Fail with an error code if a page returns an
                                  HTTP error
  --skip                          Skip pages that return HTTP errors
  --bypass-csp                    Bypass Content-Security-Policy
  --silent                        Do not output any messages
  --auth-password TEXT            Password for HTTP Basic authentication
  --auth-username TEXT            Username for HTTP Basic authentication
  --help                          Show this message and exit.
```
<!-- [[[end]]] -->

</document_content>
</document>
<document index="7">
<source>docs/index.md</source>
<document_content>
# shot-scraper

A command-line utility for taking automated screenshots of websites

**Quick start**:

```bash
pip install shot-scraper
shot-scraper install
shot-scraper https://github.com/simonw/shot-scraper -h 900
```
Produces this screenshot in a file called `github-com-simonw-shot-scraper.png`:

<img src="https://raw.githubusercontent.com/simonw/shot-scraper-screenshot/main/shot.png" alt="A screenshot of the shot-scraper page on GitHub">

**Contents**

```{toctree}
---
maxdepth: 3
---
installation
screenshots
authentication
multi
javascript
pdf
html
har
accessibility
github-actions
contributing
```
```{include} ../README.md
```

</document_content>
</document>
<document index="8">
<source>docs/installation.md</source>
<document_content>
(installation)=

# Installation

Install this tool using `pip`:
```bash
pip install shot-scraper
```
This tool depends on Playwright, which first needs to install its own dedicated Chromium browser.

Run `shot-scraper install` once to install that:
```bash
shot-scraper install
```
Which outputs:
```
Downloading Playwright build of chromium v965416 - 117.2 Mb [====================] 100% 0.0s 
Playwright build of chromium v965416 downloaded to /Users/simon/Library/Caches/ms-playwright/chromium-965416
Downloading Playwright build of ffmpeg v1007 - 1.1 Mb [====================] 100% 0.0s 
Playwright build of ffmpeg v1007 downloaded to /Users/simon/Library/Caches/ms-playwright/ffmpeg-1007
```
If you want to use other browsers such as Firefox you should install those too:
```bash
shot-scraper install -b firefox
```

## `shot-scraper install --help`

Full `--help` for the `shot-scraper install` command:
<!-- [[[cog
import cog
from shot_scraper import cli
from click.testing import CliRunner
runner = CliRunner()
result = runner.invoke(cli.cli, ["install", "--help"])
help = result.output.replace("Usage: cli", "Usage: shot-scraper")
cog.out(
    "```\n{}\n```\n".format(help.strip())
)
]]] -->
```
Usage: shot-scraper install [OPTIONS]

  Install the Playwright browser needed by this tool.

  Usage:

      shot-scraper install

  Or for browsers other than the Chromium default:

      shot-scraper install -b firefox

Options:
  -b, --browser [chromium|firefox|webkit|chrome|chrome-beta]
                                  Which browser to install
  --help                          Show this message and exit.
```
<!-- [[[end]]] -->

</document_content>
</document>
<document index="9">
<source>docs/javascript.md</source>
<document_content>
(javascript)=

# Scraping pages using JavaScript

The `shot-scraper javascript` command can be used to execute JavaScript directly against a page and return the result as JSON.

This command doesn't produce a screenshot, but has interesting applications for scraping.

To retrieve a string title of a document:
```bash
shot-scraper javascript https://datasette.io/ "document.title"
```
This returns a JSON string:
```json
"Datasette: An open source multi-tool for exploring and publishing data"
```
To return a raw string instead, use the `-r` or `--raw` options:
```bash
shot-scraper javascript https://datasette.io/ "document.title" -r
```
Output:
```
Datasette: An open source multi-tool for exploring and publishing data
```
To return a JSON object, wrap an object literal in parenthesis:
```bash
shot-scraper javascript https://datasette.io/ "({
  title: document.title,
  tagline: document.querySelector('.tagline').innerText
})"
```
This returns:
```json
{
  "title": "Datasette: An open source multi-tool for exploring and publishing data",
  "tagline": "An open source multi-tool for exploring and publishing data"
}
```
## Running more than one statement

You can use `() => { ... }` function syntax to run multiple statements, returning a result at the end of your function.

This example raises an error if no paragraphs are found.

```bash
shot-scraper javascript https://www.example.com/ "
() => {
  var paragraphs = document.querySelectorAll('p');
  if (paragraphs.length == 0) {
    throw 'No paragraphs found';
  }
  return Array.from(paragraphs, el => el.innerText);
}"
```

## Using async/await

You can pass an `async` function if you want to use `await`, including to import modules from external URLs. This example loads the [Readability.js](https://github.com/mozilla/readability) library from [jsdelivr](https://www.jsdelivr.com/) and uses it to extract the core content of a page:

```bash
shot-scraper javascript \
  https://simonwillison.net/2022/Mar/14/scraping-web-pages-shot-scraper/ "
async () => {
  const readability = await import('https://cdn.jsdelivr.net/npm/@mozilla/readability@0.6.0/+esm');
  return (new readability.Readability(document)).parse();
}"
```

To use functions such as `setInterval()`, for example if you need to delay the shot for a second to allow an animation to finish running, return a promise:
```bash
shot-scraper javascript datasette.io "
new Promise(done => setInterval(
  () => {
    done({
      title: document.title,
      tagline: document.querySelector('.tagline').innerText
    });
  }, 1000
));"
```
(bypass-csp)=
## Bypassing Content Security Policy headers

Some websites use [Content Security Policy](https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP) (CSP) headers to prevent additional JavaScript from executing on the page, as a security measure.

When using `shot-scraper` this can prevent some JavaScript features from working. You might see error messages that look like this:
```bash
shot-scraper javascript github.com "
  async () => {
    await import('https://cdn.jsdelivr.net/npm/left-pad/+esm');
    return 'content-security-policy ignored' }
"
```
Output:
```
Error: TypeError: Failed to fetch dynamically imported module:
https://cdn.jsdelivr.net/npm/left-pad/+esm
```
You can use the `--bypass-csp` option to have `shot-scraper` run the browser in a mode that ignores these headers:
```bash
shot-scraper javascript github.com "
  async () => {
    await import('https://cdn.jsdelivr.net/npm/left-pad/+esm');
    return 'content-security-policy ignored' }
" --bypass-csp
```
Output:
```
"content-security-policy ignored"
```
## Using this for automated tests

If a JavaScript error occurs, a stack trace will be written to standard error and the tool will terminate with an exit code of 1.

This can be used to run JavaScript tests in continuous integration environments, by taking advantage of the `throw "error message"` JavaScript statement.

This example [uses GitHub Actions](https://docs.github.com/en/actions/quickstart):

```yaml
- name: Test page title
  run: |-
    shot-scraper javascript datasette.io "
      if (document.title != 'Datasette') {
        throw 'Wrong title detected';
      }"
```

## Running JavaScript from a file

You can also save JavaScript to a file and execute it like this:
```bash
shot-scraper javascript datasette.io -i script.js
```
Or read it from standard input like this:
```bash
echo "document.title" | shot-scraper javascript datasette.io
```
Or read it from standard input like this:
```bash
echo "document.title" | shot-scraper javascript datasette.io
```

## Running JavaScript from GitHub

A special `gh:` prefix can be used to load scripts from GitHub.

You can use this with a full path to a `script.js` file in a public GitHub repository like this:

```bash
shot-scraper javascript datasette.io -i gh:simonw/shot-scraper-scripts/readability.js
```
Or by convention if the script lives in a repo called `shot-scraper-scripts` you can omit that (and the `.js` extension too) like this:

```bash
shot-scraper javascript datasette.io -i gh:simonw/readability
```
Both of these examples will execute [readability.js](https://github.com/simonw/shot-scraper-scripts/blob/main/readability.js), explained in the next section.

## Example: Extracting page content with Readability.js

[Readability.js](https://github.com/mozilla/readability) is "a standalone version of the readability library used for Firefox Reader View." It lets you parse the content on a web page and extract just the title, content, byline and some other key metadata.

The following recipe imports the library from the [jsdelivr CDN](https://www.jsdelivr.com/), runs it against the current page and returns the results to the console as JSON:

```bash
shot-scraper javascript https://simonwillison.net/2022/Mar/24/datasette-061/ "
async () => {
  const readability = await import('https://cdn.jsdelivr.net/npm/@mozilla/readability@0.6.0/+esm');
  return (new readability.Readability(document)).parse();
}"
```
The output looks like this:
```json
{
    "title": "Datasette 0.61: The annotated release notes",
    "byline": null,
    "dir": null,
    "lang": "en-gb",
    "content": "<div id=\"readability-page-1\" class=\"page\"><div id=\"primary\">\n\n\n\n\n<p>I released ... <this is a very long string>",
    "length": 8625,
    "excerpt": "I released Datasette 0.61 this morning\u2014closely followed by 0.61.1 to fix a minor bug. Here are the annotated release notes. In preparation for Datasette 1.0, this release includes two potentially \u2026",
    "siteName": null
}
```
See [Extracting web page content using Readability.js and shot-scraper](https://til.simonwillison.net/shot-scraper/readability) for more.

## shot-scraper javascript \-\-help

Full `--help` for this command:

<!-- [[[cog
import cog
from shot_scraper import cli
from click.testing import CliRunner
runner = CliRunner()
result = runner.invoke(cli.cli, ["javascript", "--help"])
help = result.output.replace("Usage: cli", "Usage: shot-scraper")
cog.out(
    "```\n{}\n```\n".format(help.strip())
)
]]] -->
```
Usage: shot-scraper javascript [OPTIONS] URL [JAVASCRIPT]

  Execute JavaScript against the page and return the result as JSON

  Usage:

      shot-scraper javascript https://datasette.io/ "document.title"

  To return a JSON object, use this:

      "({title: document.title, location: document.location})"

  To use setInterval() or similar, pass a promise:

      "new Promise(done => setInterval(
        () => {
          done({
            title: document.title,
            h2: document.querySelector('h2').innerHTML
          });
        }, 1000
      ));"

  If a JavaScript error occurs an exit code of 1 will be returned.

Options:
  -i, --input TEXT                Read input JavaScript from this file or use
                                  gh:username/script to load from
                                  github.com/username/shot-scraper-
                                  scripts/script.js
  -a, --auth FILENAME             Path to JSON authentication context file
  -o, --output FILENAME           Save output JSON to this file
  -r, --raw                       Output JSON strings as raw text
  -b, --browser [chromium|firefox|webkit|chrome|chrome-beta]
                                  Which browser to use
  --browser-arg TEXT              Additional arguments to pass to the browser
  --user-agent TEXT               User-Agent header to use
  --reduced-motion                Emulate 'prefers-reduced-motion' media feature
  --log-console                   Write console.log() to stderr
  --fail                          Fail with an error code if a page returns an
                                  HTTP error
  --skip                          Skip pages that return HTTP errors
  --bypass-csp                    Bypass Content-Security-Policy
  --auth-password TEXT            Password for HTTP Basic authentication
  --auth-username TEXT            Username for HTTP Basic authentication
  --help                          Show this message and exit.
```
<!-- [[[end]]] -->

</document_content>
</document>
<document index="10">
<source>docs/multi.md</source>
<document_content>
(multi)=

# Taking multiple screenshots

You can configure multiple screenshots using a YAML file. Create a file called `shots.yml` that looks like this:

```yaml
- output: example.com.png
  url: http://www.example.com/
- output: w3c.org.png
  url: https://www.w3.org/
```
Then run the tool like so:
```bash
shot-scraper multi shots.yml
```
This will create two image files, `www-example-com.png` and `w3c.org.png`, containing screenshots of those two URLs.

Use `-` to pass in YAML from standard input:
```bash
echo "- url: http://www.example.com" | shot-scraper multi -
```
If you run the tool with the `-n` or `--no-clobber` option any shots where the output file aleady exists will be skipped.

You can specify a subset of screenshots to take by specifying output files that you would like to create. For example, to take just the shots of `one.png` and `three.png` that are defined in `shots.yml` run this:
```bash
shot-scraper multi shots.yml -o one.png -o three.png
```
The `url:` can be set to a path to a file on disk as well:

```yaml
- output: index.png
  url: index.html
```

Use the `--scale-factor` option to capture all screenshots at a specific scale factor, which effectively simulates different device pixel ratios. This setting is useful for testing high-definition displays or emulating screens with various pixel densities.

For example, setting `--scale-factor 3` results in screenshots with a CSS pixel ratio of 3, which is ideal for emulating a high-resolution display, such as Apple's iPhone 12 screens.

To take screenshots with a scale factor of 3 (tripled resolution), run the following command:
```bash
shot-scraper multi shots.yml --scale-factor 3
```
This will multiply both the width and height of all screenshots by 3, resulting in images with a higher level of detail, suitable for scenarios where you need to capture the screen as it would appear on a high-DPI display.

Use `--retina` to take all screenshots at retina resolution instead, doubling the dimensions of the files:
```bash
shot-scraper multi shots.yml --retina
```
Note: The `--retina` option should not be used in conjunction with the `--scale-factor` flag as they are mutually exclusive. If both are provided, the command will raise an error to prevent conflicts.

To take a screenshot of just the area of a page defined by a CSS selector, add `selector` to the YAML block:

```yaml
- output: bighead.png
  url: https://simonwillison.net/
  selector: "#bighead"
```

You can pass more than one selector using a `selectors:` list. You can also use `padding:` to specify additional padding:

```yaml
- output: bighead-multi-selector.png
  url: https://simonwillison.net/
  selectors:
  - "#bighead"
  - .overband
  padding: 20
```

You can use `selector_all:` to capture every element matching a selector, or `selectors_all:` to pass a list of such selectors:

```yaml
- output: selectors-all.png
  url: https://simonwillison.net/
  selectors_all:
  - .day
  - .entry:nth-of-type(1)
  padding: 20
```

The `--js-selector` and `--js-selector-all` options can be provided using the `js_selector:`, `js_selectors:`, `js_selector_all:` and `js_selectors_all:` keys:

```yaml
- output: js-selector-all.png
  url: https://github.com/simonw/shot-scraper
  js_selector: |-
    el.tagName == "P" && el.innerText.includes("shot-scraper")
  padding: 20
```

To execute JavaScript after the page has loaded but before the screenshot is taken, add a `javascript` key:

```yaml
- output: bighead-pink.png
  url: https://simonwillison.net/
  selector: "#bighead"
  javascript: |
    document.body.style.backgroundColor = 'pink'
```

You can include desired `height`, `width`, `quality`, `wait` and `wait_for` options on each item as well:

```yaml
- output: simon-narrow.jpg
  url: https://simonwillison.net/
  width: 400
  height: 800
  quality: 80
  wait: 500
  wait_for: document.querySelector('#bighead')
```

(multi-har)=
## Recording to an HTTP Archive

Similar to the {ref}`shot-scraper har command<har>`, `shot-scraper multi` can optionally record HTTP Archive files of the requests made during a session.

Add the `--har` flag to record all requests and responses to a `trace.har` JSON file, or `--har-zip` for a `trace.har.zip` file. Use `--har-file filename.har` to provide a path to a custom filename - this will be recorded as JSON or zip depending on the file extension.

If you are running this against a larger number of pages you should use `--har-zip` to avoid the JSON HAR file growing so large that it causes Playwright to crash.

This example:

```bash
shot-scraper multi shots.yml --har
```
Will output something like this:
```
Screenshot of 'http://www.example.com/' written to 'example.com.png'
Screenshot of 'https://www.w3.org/' written to 'w3c.org.png'
Wrote to HAR file: trace.har
```
When writing to a HAR you can omit the `output:` key in a YAML file to skip taking a screenshot of that file. This `shots.yml` file for example:
```yaml
- url: https://example.com/
- url: https://datasette.io/
```
When run like this:
```bash
shot-scraper multi shots.yml --har-zip
```
Will produce this output, recording a HAR without taking any screenshots:
```
Skipping screenshot of 'https://example.com/'
Skipping screenshot of 'https://datasette.io/'
Wrote to HAR file: trace.har.zip
```
## Running a server for the duration of the session

If you need to run a server for the duration of the `shot-scraper multi` session you can specify that using a `server:` block, like this:
```yaml
- server: python -m http.server 8000
```
The `server:` key also accepts a list of arguments:
```yaml
- server:
  - python
  - -m
  - http.server
  - 8000
```
With that server configured, you can now take screenshots of `http://localhost:8000/` and any other URLs hosted by that server:
```yaml
- output: index.png
  url: http://localhost:8000/
```
The server process will be automatically terminated when the `shot-scraper multi` command completes, unless you pass the `--leave-server` option to `shot-scraper multi` in which case it will be left running - you can terminate it using `kill PID` with the PID displayed in the console output.

## Running custom code between steps

If you are taking screenshots of a single application, you may find it useful to run additional steps between shots that modify that application in some way.

You can do that using the `sh:` or `python:` keys. These can specify shell commands or Python code to run before taking the screenshot:

```yaml
- sh: echo "Hello from shell" > index.html
  output: from-shell.png
  url: http://localhost:8000/
```
You can also specify a list of shell arguments like this:
```yaml
- sh:
  - curl
  - -o
  - index.html
  - https://www.example.com/
  output: example.png
  url: http://localhost:8000/
```
If you specify these steps without a `url:` key they will still execute as individual task executions, without also taking a screenshot:
```yaml
- sh: echo "hello world" > index.html
- python: |
    content = open("index.html").read()
    open("index.html", "w").write(content.upper())
```

## `shot-scraper multi --help`

Full `--help` for this command:

<!-- [[[cog
import cog
from shot_scraper import cli
from click.testing import CliRunner
runner = CliRunner()
result = runner.invoke(cli.cli, ["multi", "--help"])
help = result.output.replace("Usage: cli", "Usage: shot-scraper")
cog.out(
    "```\n{}\n```\n".format(help.strip())
)
]]] -->
```
Usage: shot-scraper multi [OPTIONS] CONFIG

  Take multiple screenshots, defined by a YAML file

  Usage:

      shot-scraper multi config.yml

  Where config.yml contains configuration like this:

      - output: example.png
        url: http://www.example.com/

  For full YAML syntax documentation, see:
  https://shot-scraper.datasette.io/en/stable/multi.html

Options:
  -a, --auth FILENAME             Path to JSON authentication context file
  --scale-factor FLOAT            Device scale factor. Cannot be used together
                                  with '--retina'.
  --retina                        Use device scale factor of 2. Cannot be used
                                  together with '--scale-factor'.
  --timeout INTEGER               Wait this many milliseconds before failing
  -n, --no-clobber                Skip images that already exist
  -o, --output TEXT               Just take shots matching these output files
  -b, --browser [chromium|firefox|webkit|chrome|chrome-beta]
                                  Which browser to use
  --browser-arg TEXT              Additional arguments to pass to the browser
  --user-agent TEXT               User-Agent header to use
  --reduced-motion                Emulate 'prefers-reduced-motion' media feature
  --log-console                   Write console.log() to stderr
  --fail                          Fail with an error code if a page returns an
                                  HTTP error
  --skip                          Skip pages that return HTTP errors
  --silent                        Do not output any messages
  --auth-password TEXT            Password for HTTP Basic authentication
  --auth-username TEXT            Username for HTTP Basic authentication
  --leave-server                  Leave servers running when script finishes
  --har                           Save all requests to trace.har file
  --har-zip                       Save all requests to trace.har.zip file
  --har-file FILE                 Path to HAR file to save all requests
  --help                          Show this message and exit.
```
<!-- [[[end]]] -->

</document_content>
</document>
<document index="11">
<source>docs/pdf.md</source>
<document_content>
(pdf)=

# Saving a web page to PDF

The `shot-scraper pdf` command saves a PDF version of a web page - the equivalent of using `Print -> Save to PDF` in Chromium.

    shot-scraper pdf https://datasette.io/

This will save to `datasette-io.pdf`. You can use `-o` to specify a filename:

    shot-scraper pdf https://datasette.io/tutorials/learn-sql \
      -o learn-sql.pdf

You can pass the path to a local file on disk instead of a URL:

    shot-scraper pdf invoice.html -o invoice.pdf

## `shot-scraper pdf --help`

Full `--help` for this command:

<!-- [[[cog
import cog
from shot_scraper import cli
from click.testing import CliRunner
runner = CliRunner()
result = runner.invoke(cli.cli, ["pdf", "--help"])
help = result.output.replace("Usage: cli", "Usage: shot-scraper")
cog.out(
    "```\n{}\n```\n".format(help.strip())
)
]]] -->
```
Usage: shot-scraper pdf [OPTIONS] URL

  Create a PDF of the specified page

  Usage:

      shot-scraper pdf https://datasette.io/

  Use -o to specify a filename:

      shot-scraper pdf https://datasette.io/ -o datasette.pdf

  You can pass a path to a file instead of a URL:

      shot-scraper pdf invoice.html -o invoice.pdf

Options:
  -a, --auth FILENAME             Path to JSON authentication context file
  -o, --output FILE
  -j, --javascript TEXT           Execute this JS prior to creating the PDF
  --wait INTEGER                  Wait this many milliseconds before taking the
                                  screenshot
  --wait-for TEXT                 Wait until this JS expression returns true
  --timeout INTEGER               Wait this many milliseconds before failing
  --media-screen                  Use screen rather than print styles
  --landscape                     Use landscape orientation
  --format [Letter|Legal|Tabloid|Ledger|A0|A1|A2|A3|A4|A5|A6]
                                  Which standard paper size to use
  --width TEXT                    PDF width including units, e.g. 10cm
  --height TEXT                   PDF height including units, e.g. 10cm
  --scale FLOAT RANGE             Scale of the webpage rendering  [0.1<=x<=2.0]
  --print-background              Print background graphics
  --log-console                   Write console.log() to stderr
  --fail                          Fail with an error code if a page returns an
                                  HTTP error
  --skip                          Skip pages that return HTTP errors
  --bypass-csp                    Bypass Content-Security-Policy
  --silent                        Do not output any messages
  --auth-password TEXT            Password for HTTP Basic authentication
  --auth-username TEXT            Username for HTTP Basic authentication
  --help                          Show this message and exit.
```
<!-- [[[end]]] -->

</document_content>
</document>
<document index="12">
<source>docs/screenshots.md</source>
<document_content>
(screenshots)=

# Taking a screenshot

To take a screenshot of a web page and write it to `datasette-io.png` run this:
```bash
shot-scraper https://datasette.io/
```
If a file called `datasette-io.png` already exists the filename `datasette-io.1.png` will be used instead.

You can use the `-o` option to specify a filename:
```bash
shot-scraper https://datasette.io/ -o datasette.png
```
Use `-o -` to write the PNG image to standard output:
```bash
shot-scraper https://datasette.io/ -o - > datasette.png
```
If you omit the protocol `http://` will be added automatically, and any redirects will be followed:
```bash
shot-scraper datasette.io -o datasette.png
```
## Adjusting the browser width and height

The browser window used to take the screenshots defaults to 1280px wide and 780px tall.

You can adjust these with the `--width` and `--height` options (`-w` and `-h` for short):
```bash
shot-scraper https://datasette.io/ -o small.png --width 400 --height 800
```
If you provide both options, the resulting screenshot will be of that size. If you omit `--height` a full page length screenshot will be produced (the default).

## Screenshotting a specific area with CSS selectors

To take a screenshot of a specific element on the page, use `--selector` or `-s` with its CSS selector:
```bash
shot-scraper https://simonwillison.net/ -s '#bighead'
```
This produces `simonwillison-net.png` containing this image:

<img src="https://raw.githubusercontent.com/simonw/shot-scraper-screenshot/main/shot-selector.png" alt="Just the header section from my blog">

When using `--selector` the height and width, if provided, will set the size of the browser window when the page is loaded but the resulting screenshot will still be the same dimensions as the element on the page.

You can pass `--selector` multiple times. The resulting screenshot will cover the smallest area of the page that contains all of the elements you specified, for example:
```bash
shot-scraper https://simonwillison.net/ \
  -s '#bighead' -s .overband \
  -o bighead-multi-selector.png
```
To capture a rectangle around every element that matches a CSS selector, use `--selector-all`:
```bash
shot-scraper https://simonwillison.net/ \
  --selector-all '.day' \
  -o just-the-day-boxes.png
```
You can add `--padding 20` to add 20px of padding around the elements when the shot is taken.

## Specifying elements using JavaScript filters

The `--js-selector` and `--js-selector-all` options can be used to use JavaScript expressions to select elements that cannot be targetted just using CSS selectors.

The options should be passed JavaScript expression that operates on the `el` variable, returning `true` if that element should be included in the screenshot selection.

To take a screenshot of the first paragraph on the page that contains the text "shot-scraper" you could run the following:
```bash
shot-scraper https://github.com/simonw/shot-scraper \
  --js-selector 'el.tagName == "P" && el.innerText.includes("shot-scraper")'
```
The `el.tagName == "P"` part is needed here because otherwise the `<html>` element on the page will be the first to match the expression.

The generated JavaScript that will be executed on the page looks like this:
```javascript
Array.from(document.getElementsByTagName('*')).find(
  el => el.tagName == "P" && el.innerText.includes("shot-scraper")
).classList.add("js-selector-a1f5ba0fc4a4317e58a3bd11a0f16b96");
```
The `--js-selector-all` option will select all matching elements, in a similar fashion to the `--selector-all` option described above.

## Waiting for a delay

Sometimes a page will not have completely loaded before a screenshot is taken. You can use `--wait X` to wait the specified number of milliseconds after the page load event has fired before taking the screenshot:
```bash
shot-scraper https://simonwillison.net/ --wait 2000
```
## Waiting until a specific condition

In addition to waiting a specific amount of time, you can also wait until a JavaScript expression returns true using the `--wait-for expression` option.

This example takes the screenshot the moment a `<div>` with an ID of `content` becomes available in the DOM:
```bash
shot-scraper https://.../ \
  --wait-for 'document.querySelector("div#content")'
```
Here's an example that waits for a specific element to become available (in this case a cookie consent overlay) and then removes it before the screenshot is taken:
```bash
shot-scraper -h 800 'https://www.spiegel.de/international/' \
  --wait-for "() => {
    const div = document.querySelector('[id^="sp_message_container"]');
    if (div) {
      div.remove();
      return true;
    }
  }"
```
If the expression takes longer than 30 seconds to resolve `shot-scraper` will exit with an error.

## Executing custom JavaScript

You can use custom JavaScript to modify the page after it has loaded (after the 'onload' event has fired) but before the screenshot is taken using the `--javascript` option:
```bash
shot-scraper https://simonwillison.net/ \
  -o simonwillison-pink.png \
  --javascript "document.body.style.backgroundColor = 'pink';"
```
## Using JPEGs instead of PNGs

Screenshots default to PNG. You can save as a JPEG by specifying a `-o` filename that ends with `.jpg`.

You can also use `--quality X` to save as a JPEG with the specified quality, in order to reduce the filesize. 80 is a good value to use here:
```bash
shot-scraper https://simonwillison.net/ \
  -h 800 -o simonwillison.jpg --quality 80
```
```
% ls -lah simonwillison.jpg
-rw-r--r--@ 1 simon  staff   168K Mar  9 13:53 simonwillison.jpg
```
## Device scale factor

The `--scale-factor` option sets a specific device scale factor, which effectively simulates different device pixel ratios. This setting is useful for testing high-definition displays or emulating screens with various pixel densities.

For example, setting `--scale-factor 3` results in an image with a CSS pixel ratio of 3, which is ideal for emulating a high-resolution display, such as Apple iPhone 12 screens.

To take a screenshot with a scale factor of 3 (tripled resolution), run the following command:
```bash
shot-scraper https://simonwillison.net/ -o simon.png \
  --width 390 --height 844 --scale-factor 3
```
This will multiply both the width and height of the screenshot by 3, resulting in an image that is 1170px wide and 2532px high, matching the iPhone 12's screen.

The `--scale-factor` option takes a positive float as input. For example, setting `--scale-factor 2.625` simulates the Google Pixel 6's CSS pixel ratio.

## Retina images

The `--retina` option is a shortcut to set a device scale factor of 2. This means that an image will have its resolution effectively doubled, emulating the display of images on [retina](https://en.wikipedia.org/wiki/Retina_display) or higher pixel density screens.
```bash
shot-scraper https://simonwillison.net/ -o simon.png \
  --width 400 --height 600 --retina
```
This example will produce an image that is 800px wide and 1200px high.

Note: The `--retina` option should not be used in conjunction with the `--scale-factor` flag as they are mutually exclusive. If both are provided, the command will raise an error to prevent conflicts.

## Transparent background

The `--omit-background` option instructs the browser to ignore the default background, allowing for the capture of a page with a transparent background. Does not work with JPG images or when `quality` is set.
```bash
shot-scraper https://simonwillison.net/ -o simon.png \
  --width 400 --height 600 --omit-background
```
## Interacting with the page

Sometimes it's useful to be able to manually interact with a page before the screenshot is captured.

Add the `--interactive` option to open a browser window that you can interact with. Then hit `<enter>` in the terminal when you are ready to take the shot and close the window.
```bash
shot-scraper https://simonwillison.net/ -o after-interaction.png \
  --height 800 --interactive
```
This will output:
```
Hit <enter> to take the shot and close the browser window:
  # And after you hit <enter>...
Screenshot of 'https://simonwillison.net/' written to 'after-interaction.png'
```
## Logging all requests

It can sometimes be useful to see a list of all of the requests that the browser made while it was rendering a page.

Use `--log-requests` to output newline-delimited JSON representing each request, including requests for images and other assets.

Pass `-` to output the list to standard output, or use a filename to write to a file on disk.

The output looks like this:
```bash
shot-scraper http://datasette.io/ --log-requests -
```
```
{"method": "GET", "url": "http://datasette.io/", "status": 302, "size": null, "timing": {"startTime": 1663211674984.7068, "domainLookupStart": 0.698, "domainLookupEnd": 1.897, "connectStart": 1.897, "secureConnectionStart": -1, "connectEnd": 18.726, "requestStart": 18.86, "responseStart": 99.75, "responseEnd": 101.75000000162981}}
{"method": "GET", "url": "https://datasette.io/", "status": 200, "size": 34592, "timing": {"startTime": 1663211675085.51, "domainLookupStart": 0.187, "domainLookupEnd": 0.197, "connectStart": 0.197, "secureConnectionStart": 15.719, "connectEnd": 63.854, "requestStart": 64.098, "responseStart": 390.231, "responseEnd": 399.268}}
{"method": "GET", "url": "https://datasette.io/static/site.css", "status": 200, "size": 3952, "timing": {"startTime": 1663211675486.027, "domainLookupStart": -1, "domainLookupEnd": -1, "connectStart": -1, "secureConnectionStart": -1, "connectEnd": -1, "requestStart": 0.408, "responseStart": 99.407, "responseEnd": 100.433}}
...
```
Note that the `size` field here will be the size of the response in bytes, but in some circumstances this will not be available and it will be returned as `"size": null`.

## Browser arguments

Additional arguments to pass to the browser instance. The list of Chromium flags can be found [here](https://peter.sh/experiments/chromium-command-line-switches/).

For example, to remove font render hinting:
```bash
shot-scraper https://simonwillison.net/ -o no-hinting.png \
  --height 800 --browser-arg "--font-render-hinting=none"
```
To add multiple arguments, add `--browser-arg` for each argument:
```bash
shot-scraper https://simonwillison.net/ -o no-hinting-no-gpu.png \
  --height 800 --browser-arg "--font-render-hinting=none" --browser-arg "--disable-gpu"
```
## Taking screenshots of local HTML files

You can pass the path to an HTML file on disk to take a screenshot of that rendered file:
```bash
shot-scraper index.html -o index.png
```
CSS and images referenced from that file using relative paths will also be included.

## Tips for executing JavaScript

If you are using the `--javascript` option to execute code, that code will be executed after the page load event has fired but before the screenshot is taken.

You can use that code to do things like hide or remove specific page elements, click on links to open menus, or even add annotations to the page such as this [pink arrow example](https://simonwillison.net/2022/Mar/10/shot-scraper/#a-complex-example).

This code hides any element with a `[data-ad-rendered]` attribute and the element with `id="ensNotifyBanner"`:
```javascript
document.querySelectorAll(
    '[data-ad-rendered],#ensNotifyBanner'
).forEach(el => el.style.display = 'none')
```
You can execute that like so:

```bash
shot-scraper https://www.latimes.com/ -o latimes.png --javascript "
document.querySelectorAll(
    '[data-ad-rendered],#ensNotifyBanner'
).forEach(el => el.style.display = 'none')
"
```

In some cases you may need to add a pause that executes during your custom JavaScript before the screenshot is taken - for example if you click on a button that triggers a short fading animation.

You can do that using the following pattern:
```javascript
new Promise(takeShot => {
  // Your code goes here
  // ...
  setTimeout(() => {
    // Resolving the promise takes the shot
    takeShot();
  }, 1000);
});
```
If your custom code defines a `Promise`, `shot-scraper` will wait for that promise to complete before taking the screenshot. Here the screenshot does not occur until the `takeShot()` function is called.

If you see errors relating to CSP headers such as "Failed to fetch dynamically imported module" you can work around them using {ref}`the --bypass-csp option<bypass-csp>`.

## Viewing console.log() output

Almost all of the `shot-scraper` commands accept a `--log-console` option, which will cause them to output any calls to `console.log()` to standard error while the command is running.

This includes both `console.log()` calls in the existing page JavaScript, as well as any calls to that method that you include in your own custom JavaScript.

For example, running `--log-console` while taking a screenshot of the Facebook homepage will show this warning message, which Facebook logs to the developer tools console to help protect people from social engineering attacks:

```
% shot-scraper shot facebook.com --log-console

 .d8888b.  888                       888
d88P  Y88b 888                       888
Y88b.      888                       888    This is a browser feature intended for
 "Y888b.   888888  .d88b.  88888b.   888    developers. If someone told you to copy-paste
    "Y88b. 888    d88""88b 888 "88b  888    something here to enable a Facebook feature
      "888 888    888  888 888  888  Y8P    or "hack" someone's account, it is a
Y88b  d88P Y88b.  Y88..88P 888 d88P         scam and will give them access to your
 "Y8888P"   "Y888  "Y88P"  88888P"   888    Facebook account.
                           888
                           888
                           888

See https://www.facebook.com/selfxss for more information.

Screenshot of 'http://facebook.com' written to 'facebook-com.png'
```

## `shot-scraper shot --help`

Full `--help` for this command:

<!-- [[[cog
import cog
from shot_scraper import cli
from click.testing import CliRunner
runner = CliRunner()
result = runner.invoke(cli.cli, ["shot", "--help"])
help = result.output.replace("Usage: cli", "Usage: shot-scraper")
cog.out(
    "```\n{}\n```\n".format(help.strip())
)
]]] -->
```
Usage: shot-scraper shot [OPTIONS] URL

  Take a single screenshot of a page or portion of a page.

  Usage:

      shot-scraper www.example.com

  This will write the screenshot to www-example-com.png

  Use "-o" to write to a specific file:

      shot-scraper https://www.example.com/ -o example.png

  You can also pass a path to a local file on disk:

      shot-scraper index.html -o index.png

  Using "-o -" will output to standard out:

      shot-scraper https://www.example.com/ -o - > example.png

  Use -s to take a screenshot of one area of the page, identified using one or
  more CSS selectors:

      shot-scraper https://simonwillison.net -s '#bighead'

Options:
  -a, --auth FILENAME             Path to JSON authentication context file
  -w, --width INTEGER             Width of browser window, defaults to 1280
  -h, --height INTEGER            Height of browser window and shot - defaults
                                  to the full height of the page
  -o, --output FILE
  -s, --selector TEXT             Take shot of first element matching this CSS
                                  selector
  --selector-all TEXT             Take shot of all elements matching this CSS
                                  selector
  --js-selector TEXT              Take shot of first element matching this JS
                                  (el) expression
  --js-selector-all TEXT          Take shot of all elements matching this JS
                                  (el) expression
  -p, --padding INTEGER           When using selectors, add this much padding in
                                  pixels
  -j, --javascript TEXT           Execute this JS prior to taking the shot
  --scale-factor FLOAT            Device scale factor. Cannot be used together
                                  with '--retina'.
  --retina                        Use device scale factor of 2. Cannot be used
                                  together with '--scale-factor'.
  --omit-background               Omit the default browser background from the
                                  shot, making it possible take advantage of
                                  transparency. Does not work with JPEGs or when
                                  using --quality.
  --quality INTEGER               Save as JPEG with this quality, e.g. 80
  --wait INTEGER                  Wait this many milliseconds before taking the
                                  screenshot
  --wait-for TEXT                 Wait until this JS expression returns true
  --timeout INTEGER               Wait this many milliseconds before failing
  -i, --interactive               Interact with the page in a browser before
                                  taking the shot
  --devtools                      Interact mode with developer tools
  --log-requests FILENAME         Log details of all requests to this file
  --log-console                   Write console.log() to stderr
  -b, --browser [chromium|firefox|webkit|chrome|chrome-beta]
                                  Which browser to use
  --browser-arg TEXT              Additional arguments to pass to the browser
  --user-agent TEXT               User-Agent header to use
  --reduced-motion                Emulate 'prefers-reduced-motion' media feature
  --fail                          Fail with an error code if a page returns an
                                  HTTP error
  --skip                          Skip pages that return HTTP errors
  --bypass-csp                    Bypass Content-Security-Policy
  --silent                        Do not output any messages
  --auth-password TEXT            Password for HTTP Basic authentication
  --auth-username TEXT            Username for HTTP Basic authentication
  --help                          Show this message and exit.
```
<!-- [[[end]]] -->

</document_content>
</document>
</documents>
